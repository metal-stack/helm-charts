# Default values for postgreslet.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: r.metal-stack.io/postgreslet
  pullPolicy: IfNotPresent
  tag: "v0.12.0"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  #  A prefix to use in all the (Cluster)Roles that are being created for this service account.
  # If not set and create is true, a name is generated using the fullname template
  roleNamePrefix: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

resources:
  limits:
    cpu: 100m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

controlplaneKubeconfig: ""

terminationGracePeriodSeconds: 10

postgreslet:
  # enableLeaderElection specifies weather leader election should be performed
  enableLeaderElection: false
  # partitionId specifies which partition this postgreslet is responsable for, postgres resources from other partitions will be ignored
  partitionId: sample-partition
  # tenant specifies which tenant this postgreslet is responsable for, postgres resources from other tenants will be ignored
  tenant: sample-tenant
  # metricsAddr defines the listen address of the metrics endpoint
  metricsAddr: ":8080"
  # loadBalancerIP defines the load-balancer IP of postgres in this cluster
  # If not set one will be provisioned dynamically
  loadBalancerIP: ""
  # portRangeStart deinfes the start of the port range of services LoadBalancer
  portRangeStart: 32000
  # portRangesize defines the size of the port range of services LoadBalancer
  portRangeSize: 8000
  # customPspName The name to use for our custom psp
  # If not set, a name is generated using the fullname template
  customPspName: ""
  # storageClass The name of the storageClass to use for Postgres clusters
  storageClass: "csi-lvm-sc-mirror"
  # operatorImageRepository 
  operatorImageRepository: "docker.io/ermajn/postgres-operator"
  # operatorImageTag 
  operatorImageTag: "v1.7.0-1-g711648b-dirty"
  # postgresImageRepository 
  postgresImageRepository: "docker.io/cybertecpostgresql/spilo"
  # postgresImageTag 
  postgresImageTag: "3.0-p1_de-sync-standby-cluster_0.3.2_c52da81"
  # etcdHost The connection string for Patroni defined as host:port. Not required when native Kubernetes support is used. The default is empty (use Kubernetes-native DCS).
  etcdHost: ""
  # enableCrdValidation  toggles if the operator will create or update CRDs with OpenAPI v3 schema validation
  enableCrdValidation: true
  # postgresParamBlockList space-separated list of postgres params to ignore (see https://postgres-operator.readthedocs.io/en/latest/reference/cluster_manifest/#postgres-parameters)
  postgresParamBlockList: ""
  # majorVersionUpgradeMode defines how the operator will handle in-place version upgrades (see https://postgres-operator.readthedocs.io/en/latest/reference/operator_parameters/#major-version-upgrades)
  majorVersionUpgradeMode: "manual"
  # standbyClustersSourceRanges space-separated list of CIDRs
  standbyClustersSourceRanges: ""
  # runAsNonRoot run the operator and spilo images without root permissions
  runAsNonRoot: false
  # enableNetPol enable the use of NetworkPolicies to restrict the outgoing connections of the postgres pod
  enableNetPol: false
  # enablePodAntiaffinity enable anti-affinity of pods of the same postgres cluster, to prevent them running on the same worker node
  enablePodAntiaffinity: false
  # patroniRetryTimeout sets the patroni retry timeout, which will also result in an updated patroni ttl ( ttl=(2*retry_timeout)+10 )
  patroniRetryTimeout: 90
  # enableStandbyLeaderSelector enables the use of a new, updated selector for use with newer Spilo images. The postgreslet will use spilo-role=standby_leader in the selectors of standby DBs then.
  enableStandbyLeaderSelector: false
  # enableLegacyStandbySelector enables the old default selector. The postgreslet will use spilo-role=master in the selectors of standby DBs then.
  enableLegacyStandbySelector: false
  # enableWalGEncryption enables the client side encryption in wal_g
  enableWalGEncryption: false
  # deployEtcd enables the deployment of a dedicated etcd for this postgreslet instance
  deployEtcd: true
  # etcdImageRepository The etcd image repository to use
  etcdImageRepository: "quay.io/coreos/etcd"
  # etcdImageTag The etcd image tag to use
  etcdImageTag: "v3.5.6"
  # etcdBackupSidecarImageRepository The sidecar image repository to use
  etcdBackupSidecarImageRepository: "ghcr.io/metal-stack/backup-restore-sidecar"
  # etcdBackupSidecarImageTag The sidecar image tag to use
  etcdBackupSidecarImageTag: "v0.6.4"
  # etcdBackupSecretName The name of the K8s secret containing the s3 credentials used for backup and restore
  etcdBackupSecretName: pgaas-etcd-s3-credentials
  # etcdPspName The name of a custom PSP to use for etcd
  etcdPspName: ""
  # enableLBSourceRanges Toggles the use of loadBalancerSourceRanges on the postgres' external service
  enableLBSourceRanges: false
  # enableRandomStorageEncrytionSecret enables the generation of a random storage-encryption-secret per postgres instance
  enableRandomStorageEncrytionSecret: false

# addRandomLabel adds a random label each time the deployment.yaml is rendered, forcing k8s to update that deployment.
# In combination with image.PullPolicy=Always, this effetifely forces a reload of the pod, even if the image tag stays the same.
addRandomLabel: false

sidecars:
  fluentbit:
    imageRepository: "cr.fluentbit.io/fluent/fluent-bit"
    imageTag: "2.1.2"
    resources:
      requests:
        cpu: "100m"
        memory: "200M"
      limits:
        cpu: "500m"
        memory: "256M"
    conf: |
        [SERVICE]
            Daemon          off
            Log_Level       warn
        [INPUT]
            Name tail
            Path /home/postgres/pgdata/pgroot/pg_log/*.csv
            #DB /home/postgres/pgdata/pgroot/pg_log/postgresql.csv.pos
            Tag  psqlcsv
            Buffer_Max_Size 48k
            Skip_Long_Lines on
        [INPUT]
            Name tail
            Path /home/postgres/pgdata/pgroot/pg_log/*.log
            #DB /home/postgres/pgdata/pgroot/pg_log/postgresql.log.pos
            Tag  psqllog
            Buffer_Max_Size 48k
            Skip_Long_Lines on
        [OUTPUT]
            Name  stdout
            Match **

  exporter:
    imageRepository: "docker.io/prometheuscommunity/postgres-exporter"
    imageTag: "v0.12.1"
    containerPort: 9187
    servicePort: 9187
    resources:
      requests:
        cpu: "100m"
        memory: "200M"
      limits:
        cpu: "1"
        memory: "400M"
    queries: |+
      pg_postmaster:
        query: "SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()"
        master: true
        metrics:
          - start_time_seconds:
              usage: "GAUGE"
              description: "Time at which postmaster started"

      pg_is_in_recovery:
        query: "SELECT CASE WHEN pg_is_in_recovery = true THEN 1 ELSE 2 END AS status from pg_is_in_recovery();"
        metrics:
          - status:
              usage: "GAUGE"
              description: "Return value of 1 means database is in recovery. Otherwise 2 it is a primary."

      pg_replication_lag:
        query: "SELECT
                CASE
                WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn() THEN 0
                ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())::INTEGER
                END
              AS replay_time"
        metrics:
          - replay_time:
              usage: "GAUGE"
              description: "Length of time since the last transaction was replayed on replica. Will always increase if no writes on primary."

      pg_replication_global_status:
        query: "SELECT (extract(epoch from now()) * 1e9)::int8 as epoch_ns, application_name as tag_application_name,
                concat(coalesce(client_addr::text, client_hostname), '_', client_port::text) as tag_client_info,
                coalesce(pg_wal_lsn_diff(pg_current_wal_lsn(), write_lsn)::int8, 0) as write_lag_b,
                coalesce(pg_wal_lsn_diff(pg_current_wal_lsn(), flush_lsn)::int8, 0) as flush_lag_b,
                coalesce(pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn)::int8, 0) as replay_lag_b,
                state,
                sync_state,
                case when sync_state in ('sync', 'quorum') then 1 else 0 end as is_sync_int
              from
                pg_catalog.pg_stat_replication"
        metrics:
          - tag_application_name:
              usage: "LABEL"
              description: "Replication Database (Standby)"
          - tag_client_info:
              usage: "LABEL"
              description: "Replication Client Info (Standby)"
          - state:
              usage: "LABEL"
              description: "Replication State"
          - sync_state:
              usage: "LABEL"
              description: "Replication Sync State"
          - write_lag_b:
              usage: "GAUGE"
              description: "Replication Write Lag Master"
          - flush_lag_b:
              usage: "GAUGE"
              description: "Replication Flush Lag Master"
          - replay_lag_b:
              usage: "GAUGE"
              description: "Replication Replay Lag Master"

      pg_replication_global_status_standby:
        query: "select
              (extract(epoch from now()) * 1e9)::int8 as epoch_ns,
              pg_wal_lsn_diff(pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn()) as replay_lag_b,
              extract(epoch from (now() - pg_last_xact_replay_timestamp()))::int8 as last_replay_s;"
        metrics:
          - replay_lag_b:
              usage: "GAUGE"
              description: "Replication Replay Lag Standby"
          - last_replay_s:
              usage: "GAUGE"
              description: "Last Replication Lag Time Standby"


      pg_replication_lag_size:
        query: "SELECT client_addr as replica
              , client_hostname as replica_hostname
              , client_port as replica_port
              , pg_wal_lsn_diff(sent_lsn, replay_lsn) as bytes
              FROM pg_catalog.pg_stat_replication"
        metrics:
          - replica:
              usage: "LABEL"
              description: "Replica address"
          - replica_hostname:
              usage: "LABEL"
              description: "Replica hostname"
          - replica_port:
              usage: "LABEL"
              description: "Replica port"
          - bytes:
              usage: "GAUGE"
              description: "Replication lag in bytes"

      pg_replication_slots:
        query: "SELECT slot_name, active::int, pg_wal_lsn_diff(pg_current_wal_insert_lsn(), restart_lsn) AS retained_bytes FROM pg_catalog.pg_replication_slots"
        metrics:
          - slot_name:
              usage: "LABEL"
              description: "Name of replication slot"
          - active:
              usage: "GAUGE"
              description: "Active state of slot. 1 = true. 0 = false."
          - retained_bytes:
              usage: "GAUGE"
              description: "The amount of WAL (in bytes) being retained for this slot"

      pg_wal_activity:
        query: "SELECT last_5_min_size_bytes,
            (SELECT COALESCE(sum(size),0) FROM pg_catalog.pg_ls_waldir()) AS total_size_bytes
            FROM (SELECT COALESCE(sum(size),0) AS last_5_min_size_bytes FROM pg_catalog.pg_ls_waldir() WHERE modification > CURRENT_TIMESTAMP - '5 minutes'::interval) x;"
        metrics:
          - last_5_min_size_bytes:
              usage: "GAUGE"
              description: "Current size in bytes of the last 5 minutes of WAL generation. Includes recycled WALs."
          - total_size_bytes:
              usage: "GAUGE"
              description: "Current size in bytes of the WAL directory"

      pg_archive_command_status:
        query: "SELECT CASE
          WHEN EXTRACT(epoch from (last_failed_time - last_archived_time)) IS NULL THEN 0
          WHEN EXTRACT(epoch from (last_failed_time - last_archived_time)) < 0 THEN 0
          ELSE EXTRACT(epoch from (last_failed_time - last_archived_time))
          END AS seconds_since_last_fail
          FROM pg_catalog.pg_stat_archiver"
        metrics:
          - seconds_since_last_fail:
              usage: "GAUGE"
              description: "Seconds since the last recorded failure of the archive_command"

      pg_stat_user_tables:
        query: "SELECT current_database() datname, schemaname, relname, seq_scan, seq_tup_read, idx_scan, idx_tup_fetch, n_tup_ins, n_tup_upd, n_tup_del, n_tup_hot_upd, n_live_tup, n_dead_tup, n_mod_since_analyze, COALESCE(last_vacuum, '1970-01-01Z'), COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum, COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum, COALESCE(last_analyze, '1970-01-01Z') as last_analyze, COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze, vacuum_count, autovacuum_count, analyze_count, autoanalyze_count FROM pg_stat_user_tables"
        metrics:
          - datname:
              usage: "LABEL"
              description: "Name of current database"
          - schemaname:
              usage: "LABEL"
              description: "Name of the schema that this table is in"
          - relname:
              usage: "LABEL"
              description: "Name of this table"
          - seq_scan:
              usage: "COUNTER"
              description: "Number of sequential scans initiated on this table"
          - seq_tup_read:
              usage: "COUNTER"
              description: "Number of live rows fetched by sequential scans"
          - idx_scan:
              usage: "COUNTER"
              description: "Number of index scans initiated on this table"
          - idx_tup_fetch:
              usage: "COUNTER"
              description: "Number of live rows fetched by index scans"
          - n_tup_ins:
              usage: "COUNTER"
              description: "Number of rows inserted"
          - n_tup_upd:
              usage: "COUNTER"
              description: "Number of rows updated"
          - n_tup_del:
              usage: "COUNTER"
              description: "Number of rows deleted"
          - n_tup_hot_upd:
              usage: "COUNTER"
              description: "Number of rows HOT updated (i.e., with no separate index update required)"
          - n_live_tup:
              usage: "GAUGE"
              description: "Estimated number of live rows"
          - n_dead_tup:
              usage: "GAUGE"
              description: "Estimated number of dead rows"
          - n_mod_since_analyze:
              usage: "GAUGE"
              description: "Estimated number of rows changed since last analyze"
          - last_vacuum:
              usage: "GAUGE"
              description: "Last time at which this table was manually vacuumed (not counting VACUUM FULL)"
          - last_autovacuum:
              usage: "GAUGE"
              description: "Last time at which this table was vacuumed by the autovacuum daemon"
          - last_analyze:
              usage: "GAUGE"
              description: "Last time at which this table was manually analyzed"
          - last_autoanalyze:
              usage: "GAUGE"
              description: "Last time at which this table was analyzed by the autovacuum daemon"
          - vacuum_count:
              usage: "COUNTER"
              description: "Number of times this table has been manually vacuumed (not counting VACUUM FULL)"
          - autovacuum_count:
              usage: "COUNTER"
              description: "Number of times this table has been vacuumed by the autovacuum daemon"
          - analyze_count:
              usage: "COUNTER"
              description: "Number of times this table has been manually analyzed"
          - autoanalyze_count:
              usage: "COUNTER"
              description: "Number of times this table has been analyzed by the autovacuum daemon"

      pg_statio_user_tables:
        query: "SELECT current_database() datname, schemaname, relname, heap_blks_read, heap_blks_hit, idx_blks_read, idx_blks_hit, toast_blks_read, toast_blks_hit, tidx_blks_read, tidx_blks_hit FROM pg_statio_user_tables"
        metrics:
          - datname:
              usage: "LABEL"
              description: "Name of current database"
          - schemaname:
              usage: "LABEL"
              description: "Name of the schema that this table is in"
          - relname:
              usage: "LABEL"
              description: "Name of this table"
          - heap_blks_read:
              usage: "COUNTER"
              description: "Number of disk blocks read from this table"
          - heap_blks_hit:
              usage: "COUNTER"
              description: "Number of buffer hits in this table"
          - idx_blks_read:
              usage: "COUNTER"
              description: "Number of disk blocks read from all indexes on this table"
          - idx_blks_hit:
              usage: "COUNTER"
              description: "Number of buffer hits in all indexes on this table"
          - toast_blks_read:
              usage: "COUNTER"
              description: "Number of disk blocks read from this table's TOAST table (if any)"
          - toast_blks_hit:
              usage: "COUNTER"
              description: "Number of buffer hits in this table's TOAST table (if any)"
          - tidx_blks_read:
              usage: "COUNTER"
              description: "Number of disk blocks read from this table's TOAST table indexes (if any)"
          - tidx_blks_hit:
              usage: "COUNTER"
              description: "Number of buffer hits in this table's TOAST table indexes (if any)"

      pg_wal_activity:
        query: "SELECT last_5_min_size_bytes,
            (SELECT COALESCE(sum(size),0) FROM pg_catalog.pg_ls_waldir()) AS total_size_bytes
            FROM (SELECT COALESCE(sum(size),0) AS last_5_min_size_bytes FROM pg_catalog.pg_ls_waldir() WHERE modification > CURRENT_TIMESTAMP - '5 minutes'::interval) x;"
        metrics:
          - last_5_min_size_bytes:
              usage: "GAUGE"
              description: "Current size in bytes of the last 5 minutes of WAL generation. Includes recycled WALs."
          - total_size_bytes:
              usage: "GAUGE"
              description: "Current size in bytes of the WAL directory"

      pg_database:
        query: "SELECT pg_database.datname, pg_database_size(pg_database.datname) as size FROM pg_database"
        metrics:
          - datname:
              usage: "LABEL"
              description: "Name of the database"
          - size:
              usage: "GAUGE"
              description: "Disk space used by the database"
    queriesStatements: |+
      pg_stat_statements:
        query: "SELECT
                    pg_get_userbyid(userid) as user,
                    pg_database.datname,
                    pg_stat_statements.queryid,
                    pg_stat_statements.query,
                    pg_stat_statements.calls,
                    pg_stat_statements.total_time as time_milliseconds,
                    pg_stat_statements.rows,
                    pg_stat_statements.shared_blks_hit,
                    pg_stat_statements.shared_blks_read,
                    pg_stat_statements.shared_blks_dirtied,
                    pg_stat_statements.shared_blks_written,
                    pg_stat_statements.local_blks_hit,
                    pg_stat_statements.local_blks_read,
                    pg_stat_statements.local_blks_dirtied,
                    pg_stat_statements.local_blks_written,
                    pg_stat_statements.temp_blks_read,
                    pg_stat_statements.temp_blks_written,
                    pg_stat_statements.blk_read_time,
                    pg_stat_statements.blk_write_time
                FROM pg_stat_statements
                JOIN pg_database
                ON pg_database.oid = pg_stat_statements.dbid"
        metrics:
            - user:
                usage: "LABEL"
                description: "The user who executed the statement"
            - datname:
                usage: "LABEL"
                description: "The database in which the statement was executed"
            - queryid:
                usage: "LABEL"
                description: "Internal hash code, computed from the statement's parse tree"
            - query:
                usage: "LABEL"
                description: "Processed query"
            - calls:
                usage: "COUNTER"
                description: "Number of times executed"
            - time_milliseconds:
                usage: "COUNTER"
                description: "Total time spent in the statement, in milliseconds"
            - rows:
                usage: "COUNTER"
                description: "Total number of rows retrieved or affected by the statement"
            - shared_blks_hit:
                usage: "COUNTER"
                description: "Total number of shared block cache hits by the statement"
            - shared_blks_read:
                usage: "COUNTER"
                description: "Total number of shared blocks read by the statement"
            - shared_blks_dirtied:
                usage: "COUNTER"
                description: "Total number of shared blocks dirtied by the statement"
            - shared_blks_written:
                usage: "COUNTER"
                description: "Total number of shared blocks written by the statement"
            - local_blks_hit:
                usage: "COUNTER"
                description: "Total number of local block cache hits by the statement"
    enableStatementsQuery: false

